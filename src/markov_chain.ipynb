{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "markov_chain.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtCuYyrB6zWh",
        "colab_type": "code",
        "outputId": "6fe4a0f4-5b89-40ea-b623-fbeecde2d985",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!git clone https://github.com/michalovsky/books-data.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'books-data'...\n",
            "remote: Enumerating objects: 84, done.\u001b[K\n",
            "remote: Counting objects: 100% (84/84), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 84 (delta 21), reused 63 (delta 14), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (84/84), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a09xu_8D8viL",
        "colab_type": "code",
        "outputId": "0e46ff66-a8ec-47da-c325-417bc2c8a09f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import glob\n",
        "\n",
        "def read_data(directory):\n",
        "  file_paths = glob.glob(directory +\"*.txt\")    \n",
        "  text = \"\"\n",
        "  for file_path in file_paths:\n",
        "    with open(file_path, 'r', encoding=\"utf-8-sig\") as file:\n",
        "      file_content = file.read()\n",
        "      text+=file_content\n",
        "  return text\n",
        "\n",
        "directory = \"books-data/kafka/\"\n",
        "\n",
        "text = read_data(directory)\n",
        "print ('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 571642 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOTq-H4K9QX-",
        "colab_type": "code",
        "outputId": "3fe400e4-32cf-4e70-9edb-9928ceeffe48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import string\n",
        "\n",
        "class DataProcessor:\n",
        "\tdef __init__(self, chars_to_remove, chars_to_translate, replacement_chars):\n",
        "\t\tself.chars_to_remove = chars_to_remove\n",
        "\t\tself.chars_to_translate = chars_to_translate\n",
        "\t\tself.replacement_chars = replacement_chars\n",
        "\n",
        "\tdef preprocess_data(self, text):\n",
        "\t\tremoval_translator = str.maketrans(\"\", \"\", self.chars_to_remove)\n",
        "\t\tspecial_characters_translator = str.maketrans(self.chars_to_translate, self.replacement_chars , '')\n",
        "\t\ttext = text.lower().translate(removal_translator).translate(special_characters_translator)\n",
        "\t\ttext = \"\".join( list( map(DataProcessor.__split_punctuation_from_sentence , text)))\n",
        "\t\ttext = \" \".join(text.split())\n",
        "\t\treturn text\n",
        "\t\n",
        "\t@staticmethod\n",
        "\tdef __split_punctuation_from_sentence(char):\n",
        "\t\tif (char == '.' or char == ','):\n",
        "\t\t  return (\" \" + char + \" \")\n",
        "\t\telse:\n",
        "\t\t\treturn (char)\n",
        "\n",
        "characters_to_remove = '–—”„…«»‘’“°ſ†•✠' + '!\\\"#$%&\\'()*+-/:;<=>?@[\\]^_`{|}~' + string.digits  \n",
        "characters_to_translate = 'ąćęłńóśźżäöüæèêéôâáà£çëîñòùúûāœï'\n",
        "replacement_characters = 'acelnoszzaoueeeeoaaaeceinouuuaei'\n",
        "\n",
        "dataprocessor = DataProcessor(characters_to_remove, characters_to_translate, replacement_characters)\n",
        "text = dataprocessor.preprocess_data(text)\n",
        "\n",
        "words = text.split()\n",
        "print('Total words:', len(words))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total words: 117176\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjnxpLKC-1-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_pairs_n_1(words):\n",
        "  for i in range(len(words) - 1):\n",
        "    yield (words[i], words[i + 1])\n",
        "\n",
        "def make_pairs_n_2(words):\n",
        "  for i in range(len(words) - 2):\n",
        "    yield (words[i] + \" \" + words[i+1], words[i + 2])\n",
        "\n",
        "pairs = make_pairs_n_2(words)\n",
        "\n",
        "word_dict = {}\n",
        "for word_1, word_2 in pairs:\n",
        "  if word_1 in word_dict.keys():\n",
        "    word_dict[word_1].append(word_2)\n",
        "  else:\n",
        "    word_dict[word_1] = [word_2]\n",
        "\n",
        "from collections import Counter\n",
        "for key in word_dict:\n",
        "  cnt = Counter(word_dict[key])\n",
        "  word_dict[key] = cnt.most_common(1)[0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0N1JLe4_hmF",
        "colab_type": "code",
        "outputId": "8be3b8f7-fff0-4a8a-fdb0-8599ab9a583e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "next_input = \"years that\"\n",
        "chain = [next_input]\n",
        " \n",
        "n_words = 100\n",
        "for i in range(n_words):\n",
        "  second_word = next_input.split()[1]\n",
        "  prediction = word_dict[next_input]\n",
        "  chain.append(prediction)\n",
        "  next_input = second_word + \" \" + prediction\n",
        "\n",
        "print(' '.join(chain))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "years that he had been waiting for you , said the painter , and he was not possible to see him . he had been waiting for you , said the painter , and he was not possible to see him . he had been waiting for you , said the painter , and he was not possible to see him . he had been waiting for you , said the painter , and he was not possible to see him . he had been waiting for you , said the painter , and he was not possible to see him .\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}